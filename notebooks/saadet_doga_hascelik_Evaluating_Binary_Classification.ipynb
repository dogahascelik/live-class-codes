{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-iRvitW_mOmI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZTL4F90RnqNA"
   },
   "outputs": [],
   "source": [
    "# https://www.statsmodels.org/stable/index.html\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jrjModelRegistry'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33menvs Loaded\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m     load_dotenv(dotenv_path=env_path)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjrjModelRegistry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjrjModelRegistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m registerAJrjModel\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'jrjModelRegistry'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path(\"../../.env-live\")\n",
    "\n",
    "if env_path.exists():\n",
    "    print('envs Loaded')\n",
    "    load_dotenv(dotenv_path=env_path)\n",
    "from jrjModelRegistry.jrjModelRegistry import registerAJrjModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalRegressionPredictor(self, transformedData):\n",
    "    return self.predict(transformedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fK4vZwBPnA5z"
   },
   "outputs": [],
   "source": [
    "spamDf = pd.read_excel(\"./Spam.xlsx\")\n",
    "# spamDf = pd.read_excel(\"https://www.dropbox.com/scl/fi/v24mmhg5hmefmnv99uqsy/Spam.xlsx?rlkey=iq7exnueq84sy7y2b8ud70mp0&dl=1\")\n",
    "spamDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgPRgw9TnYLJ"
   },
   "outputs": [],
   "source": [
    "spamDf.size, spamDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationBinaryCalssifiactionSampleData = {\n",
    "    \"Recipients\": [19, 15, 13],\n",
    "    \"Hyperlinks\": [1, 1, 11],\n",
    "    \"Characters\": [47, 58, 88]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationBinaryCalssifiactionTransformer(dataForTransfer = None):\n",
    "    import pandas as pd\n",
    "    import statsmodels.api as sm\n",
    "    if isinstance(dataForTransfer, pd.DataFrame):\n",
    "        df = dataForTransfer.copy()\n",
    "    else:\n",
    "        df = pd.DataFrame(dataForTransfer)\n",
    "    dfTransformer = sm.add_constant(df[[\"Recipients\", \"Hyperlinks\", \"Characters\"]],has_constant='add')\n",
    "    return dfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqcLaMdZoasO"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_JGlYFloXHm"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "trainSet, testSet = train_test_split(\n",
    "  spamDf,\n",
    "  test_size=0.3,\n",
    "  random_state=1,\n",
    "  stratify=spamDf['Spam']\n",
    ")\n",
    "trainSet.shape, testSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8pFCQgIpAu3"
   },
   "outputs": [],
   "source": [
    "# Fit the logistic regression model\n",
    "features = ['Recipients', 'Hyperlinks', 'Characters']\n",
    "xTrain = trainSet[features]\n",
    "yTrain = trainSet['Spam'].astype(int)\n",
    "yTest = testSet['Spam'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sHvxFpspMKh"
   },
   "outputs": [],
   "source": [
    "model1 = sm.Logit(\n",
    "  yTrain,\n",
    "  evaluationBinaryCalssifiactionTransformer(xTrain)\n",
    ")\n",
    "model1Fit = model1.fit()\n",
    "print(model1Fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YbGrnLcp4EK"
   },
   "outputs": [],
   "source": [
    "predict1 = model1Fit.predict(evaluationBinaryCalssifiactionTransformer(testSet))\n",
    "testSet['predict1'] = predict1\n",
    "sumTable = pd.DataFrame({'A': testSet['Spam'], 'Prob': testSet['predict1']})\n",
    "sumTable.to_csv(\"ROC.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet['predict1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnM895bnYFuU"
   },
   "outputs": [],
   "source": [
    "sumTable1 = pd.DataFrame({'A': testSet['Spam'], 'Prob': testSet['predict1']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0GKRfOerVZk"
   },
   "outputs": [],
   "source": [
    "# Make predictions based on probability threshold of 0.5\n",
    "testSet['predictions'] = (testSet['predict1'] > 0.5).astype(int)\n",
    "sumTable1['P'] = testSet['predictions']\n",
    "sumTable1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlQk7hqYsHwL"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FS8w-2ysIlk"
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(sumTable1['A'], sumTable1['P'])\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuSL_r7AsYT3"
   },
   "outputs": [],
   "source": [
    "# Calculate recall\n",
    "recall = recall_score(sumTable1['A'], sumTable1['P'])\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NicDWx4esa9G"
   },
   "outputs": [],
   "source": [
    "# Calculate precision\n",
    "precision = precision_score(sumTable1['A'], sumTable1['P'])\n",
    "print(f'Precision: {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SgxhSyW-spz7"
   },
   "outputs": [],
   "source": [
    "# Sensitivity and Specificity (Sensitivity is same as recall)\n",
    "sensitivity = recall\n",
    "specificity = sum((sumTable1['A'] == 0) & (sumTable1['P'] == 0)) / sum(sumTable1['A'] == 0)\n",
    "print(f'Sensitivity: {sensitivity}')\n",
    "print(f'Specificity: {specificity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4Bufrh8tPIp"
   },
   "outputs": [],
   "source": [
    "# Calculate F1 Score\n",
    "f1Score = 2 * (precision * recall) / (precision + recall)\n",
    "print(f'F1 Score: {f1Score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NS_N1R_tcf9"
   },
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(testSet['Spam'], testSet['predict1'])\n",
    "roc_auc = roc_auc_score(testSet['Spam'], testSet['predict1'])\n",
    "# Calculate AUC\n",
    "print(f'AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZLGYNGpuGWY"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1K-2SMbUt90Z"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1Fit.transformer = evaluationBinaryCalssifiactionTransformer\n",
    "model1Fit.mainPredictor = partial(generalRegressionPredictor, model1Fit)\n",
    "registerAJrjModel(\n",
    "    model1Fit,\n",
    "    {\n",
    "        \"modelName\":f\"saadet_doga_hascelik__evaluationBinaryCalssifiactionModelWithExteraMetircs\",\n",
    "        \"version\":\"1.0.1\",\n",
    "        \"params\": model1Fit.params.to_dict(),\n",
    "        \"score\": accuracy,\n",
    "        \"otherEvaluationMetrics\": {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"recall\": recall,\n",
    "            \"precision\": precision,\n",
    "            \"sensitivity\": sensitivity,\n",
    "            \"specificity\": specificity,\n",
    "            \"f1Score\": f1Score,\n",
    "            \"roc_auc\": roc_auc,\n",
    "        },\n",
    "        \"modelLibrary\": \"statsmodels.api.Logit\",\n",
    "        \"libraryMetadata\": {\n",
    "            \"pvalues\": model1Fit.pvalues.to_dict(),\n",
    "            \"pseudo_r_squared\": float(model1Fit.prsquared),\n",
    "            \"llf\": float(model1Fit.llf),\n",
    "            \"aic\": float(model1Fit.aic),\n",
    "            \"bic\": float(model1Fit.bic)\n",
    "        },\n",
    "    \n",
    "        \"sampleData\": {\n",
    "            \"dataForTransfer\": evaluationBinaryCalssifiactionSampleData\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalDtPredictor(self, transformedData):\n",
    "    import pandas as pd\n",
    "    probs = self.predict_proba(transformedData)\n",
    "    return pd.Series(probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalDtTransformer(dataForTransfer = None):\n",
    "    import pandas as pd\n",
    "    if isinstance(dataForTransfer, pd.DataFrame):\n",
    "        df = dataForTransfer.copy()\n",
    "    else:\n",
    "        df = pd.DataFrame(dataForTransfer)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(evaluationBinaryCalssifiactionTransformer(xTrain), yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required packages for visualization\n",
    "from IPython.display import Image  \n",
    "from six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus, graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tree with max_depth=3\n",
    "dot_data = StringIO()  \n",
    "\n",
    "export_graphviz(dt, out_file=dot_data, filled=True, rounded=True,\n",
    "                feature_names=evaluationBinaryCalssifiactionTransformer(xTrain).columns, \n",
    "                class_names=['No Disease', \"Disease\"])\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())\n",
    "#Image(graph.create_png(),width=800,height=900)\n",
    "#graph.write_pdf(\"dt_heartdisease.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = dt.predict(evaluationBinaryCalssifiactionTransformer(xTrain))\n",
    "y_test_pred = dt.predict(evaluationBinaryCalssifiactionTransformer(testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(yTrain, y_train_pred))\n",
    "confusion_matrix(yTrain, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(yTest, y_test_pred))\n",
    "confusion_matrix(yTest, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.transformer = evaluationBinaryCalssifiactionTransformer\n",
    "dt.mainPredictor = partial(generalDtPredictor,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(evaluationBinaryCalssifiactionTransformer(evaluationBinaryCalssifiactionTransformer(testSet)))\n",
    "# y_pred\n",
    "score = accuracy_score(yTest, y_pred)\n",
    "# score\n",
    "report = classification_report(yTest, y_pred, output_dict=True)\n",
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_metadata = {\n",
    "    \"modelName\": \"saadet_Doga_hascelik__evaluationBinaryCalssifiactionModelDt\",\n",
    "    \"version\": \"1.0.1\",\n",
    "    \"params\": dt.get_params(),  # All model hyperparameters\n",
    "    \"score\": float(score),         # Accuracy\n",
    "    \"modelLibrary\": \"sklearn.tree.DecisionTreeClassifier\",\n",
    "    \"libraryMetadata\": {\n",
    "        \"feature_importances\": dt.feature_importances_.tolist(),\n",
    "        \"n_features\": int(dt.n_features_in_),\n",
    "        \"n_classes\": int(dt.n_classes_),\n",
    "        \"classes\": dt.classes_.tolist(),\n",
    "        \"depth\": int(dt.get_depth()),\n",
    "        \"n_leaves\": int(dt.get_n_leaves()),\n",
    "        \"classification_report\": report\n",
    "    },\n",
    "     \"sampleData\": {\n",
    "        \"dataForTransfer\": evaluationBinaryCalssifiactionSampleData\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registerAJrjModel(\n",
    "    dt,\n",
    "    dt_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = DecisionTreeClassifier(min_samples_leaf=20, random_state=42, criterion=\"entropy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1.fit(evaluationBinaryCalssifiactionTransformer(xTrain), yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()  \n",
    "\n",
    "export_graphviz(dt1, out_file=dot_data, filled=True, rounded=True,\n",
    "                feature_names=evaluationBinaryCalssifiactionTransformer(xTrain).columns, \n",
    "                class_names=['No Disease', \"Disease\"])\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())\n",
    "#Image(graph.create_png(),width=800,height=900)\n",
    "#graph.write_pdf(\"dt_heartdisease.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1.transformer = evaluationBinaryCalssifiactionTransformer\n",
    "dt1.mainPredictor = partial(generalDtPredictor,dt1)\n",
    "y_pred = dt.predict(evaluationBinaryCalssifiactionTransformer(evaluationBinaryCalssifiactionTransformer(testSet)))\n",
    "# y_pred\n",
    "score = accuracy_score(yTest, y_pred)\n",
    "# score\n",
    "report = classification_report(yTest, y_pred, output_dict=True)\n",
    "# report\n",
    "dt1_metadata = {\n",
    "    \"modelName\": \"saadet_doga_hascelik__evaluationBinaryCalssifiactionModelDt1\",\n",
    "    \"version\": \"1.0.1\",\n",
    "    \"params\": dt1.get_params(),  # All model hyperparameters\n",
    "    \"score\": float(score),         # Accuracy\n",
    "    \"modelLibrary\": \"sklearn.tree.DecisionTreeClassifier\",\n",
    "    \"libraryMetadata\": {\n",
    "        \"feature_importances\": dt1.feature_importances_.tolist(),\n",
    "        \"n_features\": int(dt1.n_features_in_),\n",
    "        \"n_classes\": int(dt1.n_classes_),\n",
    "        \"classes\": dt1.classes_.tolist(),\n",
    "        \"depth\": int(dt1.get_depth()),\n",
    "        \"n_leaves\": int(dt1.get_n_leaves()),\n",
    "        \"classification_report\": report\n",
    "    },\n",
    "     \"sampleData\": {\n",
    "        \"dataForTransfer\": evaluationBinaryCalssifiactionSampleData\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registerAJrjModel(\n",
    "    dt1,\n",
    "    dt1_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
